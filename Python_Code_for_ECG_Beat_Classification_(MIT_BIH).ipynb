{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohkmh/my-new-rep/blob/main/Python_Code_for_ECG_Beat_Classification_(MIT_BIH).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Script for ECG beat classification (Normal vs. VEB) using MIT-BIH data.\n",
        "\"\"\"\n",
        "\n",
        "import wfdb # للتعامل مع بيانات PhysioNet\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.signal as signal\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# سنستخدم Random Forest كمصنف (قوي وجيد كبداية)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import seaborn as sns\n",
        "import os # للتحقق من وجود مجلد البيانات\n",
        "\n",
        "# -------------------------------------------\n",
        "# 0. إعدادات وتحميل البيانات\n",
        "# Settings and Data Loading\n",
        "# -------------------------------------------\n",
        "# تحديد رقم التسجيل وقناة الإشارة (عادةً القناة الأولى هي MLII)\n",
        "# Specify record name and signal channel (usually the first channel is MLII)\n",
        "record_name = '101' # مثال لتسجيل يحتوي على نبضات طبيعية و VEBs (Example record with Normal and VEB beats)\n",
        "channel = 0\n",
        "data_dir = 'mit_bih_data' # مجلد لتخزين بيانات physionet (Folder to store PhysioNet data)\n",
        "\n",
        "# التأكد من وجود المجلد وإنشائه إذا لم يكن موجودًا\n",
        "# Ensure the directory exists, create it if not\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "    print(f\"Created directory: {data_dir}\")\n",
        "\n",
        "# تحميل بيانات التسجيل (الإشارة والبيانات الوصفية)\n",
        "# Load record data (signal and metadata)\n",
        "# download=True سيقوم بتحميل البيانات إذا لم تكن موجودة في data_dir\n",
        "# download=True will download data if not present in data_dir\n",
        "try:\n",
        "    print(f\"Attempting to load record '{record_name}' from PhysioNet MIT-BIH database...\")\n",
        "    record = wfdb.rdrecord(f'{record_name}', sampfrom=0, sampto=None, # sampto=30000 لتحميل جزء فقط (to load only a part)\n",
        "                           channels=[channel], pb_dir='mitdb', # pb_dir يحدد قاعدة البيانات على PhysioNet (specifies the database on PhysioNet)\n",
        "                           data_dir=data_dir) # تحديد المجلد المحلي (Specify local directory)\n",
        "    # تحميل التعليقات التوضيحية (أنواع النبضات ومواقعها)\n",
        "    # Load annotations (beat types and locations)\n",
        "    annotation = wfdb.rdann(f'{record_name}', 'atr', sampfrom=0, sampto=None, # sampto=30000\n",
        "                            pb_dir='mitdb', data_dir=data_dir)\n",
        "    print(\"Record and annotations loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading record {record_name}: {e}\")\n",
        "    print(\"Please ensure you have an internet connection for the first download,\")\n",
        "    print(f\"or that the data exists in the specified directory: {data_dir}\")\n",
        "    exit()\n",
        "\n",
        "# استخلاص الإشارة ومعدل أخذ العينات\n",
        "# Extract signal and sampling rate\n",
        "ecg_signal = record.p_signal[:, 0] # أخذ القناة الأولى (Take the first channel)\n",
        "fs = record.fs\n",
        "print(f\"Loaded record: {record_name}, Sampling rate: {fs} Hz, Signal length: {len(ecg_signal)} samples\")\n",
        "\n",
        "# استخلاص مواقع النبضات وأنواعها من التعليقات التوضيحية\n",
        "# Extract beat locations and types from annotations\n",
        "beat_indices = annotation.sample\n",
        "beat_symbols = annotation.symbol\n",
        "print(f\"Number of annotated beats: {len(beat_indices)}\")\n",
        "print(f\"Unique beat symbols found: {np.unique(beat_symbols)}\")\n",
        "\n",
        "# -------------------------------------------\n",
        "# 1. معالجة أولية بسيطة للإشارة (اختياري لكن موصى به)\n",
        "# Simple Signal Preprocessing (Optional but recommended)\n",
        "# -------------------------------------------\n",
        "# إزالة انحراف خط الأساس\n",
        "# Remove baseline wander using a high-pass filter\n",
        "order_hp = 4\n",
        "cutoff_hp = 0.5 # هرتز (Hz)\n",
        "b_hp, a_hp = signal.butter(order_hp, cutoff_hp, btype='highpass', fs=fs)\n",
        "ecg_filtered = signal.filtfilt(b_hp, a_hp, ecg_signal)\n",
        "print(\"Applied high-pass filter for baseline wander removal.\")\n",
        "\n",
        "# -------------------------------------------\n",
        "# 2. اكتشاف قمم R (يمكن استخدام المكتشف أو التعليقات التوضيحية)\n",
        "# R-peak Detection (Can use a detector or annotations)\n",
        "# -------------------------------------------\n",
        "# في هذا المثال، سنستخدم مواقع النبضات من التعليقات التوضيحية *الموثوقة*\n",
        "# كبديل لاكتشاف R-peaks، لضمان دقة مواقع النبضات وأنواعها.\n",
        "# (في تطبيق حقيقي، ستحتاج إلى خوارزمية اكتشاف R-peak قوية)\n",
        "# In this example, we use the *reliable* beat locations from annotations\n",
        "# instead of an R-peak detector, ensuring accurate beat locations and types.\n",
        "# (In a real application, you would need a robust R-peak detection algorithm)\n",
        "rpeak_indices_annotated = beat_indices\n",
        "print(f\"Using {len(rpeak_indices_annotated)} annotated R-peak locations.\")\n",
        "\n",
        "# -------------------------------------------\n",
        "# 3. استخلاص قطع النبضات (Beat Segmentation) وتحديد الفئات\n",
        "# Beat Segmentation and Class Definition\n",
        "# -------------------------------------------\n",
        "# تحديد الفئات المستهدفة (طبيعي 'N' و VEB 'V')\n",
        "# Define target classes (Normal 'N' and VEB 'V')\n",
        "# رموز MIT-BIH للطبيعي تشمل 'N', 'L', 'R', 'e', 'j' (سنعتبرها كلها 'N')\n",
        "# MIT-BIH symbols for Normal include 'N', 'L', 'R', 'e', 'j' (we'll consider them all 'N')\n",
        "# رموز VEB تشمل 'V', 'E' (سنعتبرها كلها 'V')\n",
        "# VEB symbols include 'V', 'E' (we'll consider them all 'V')\n",
        "target_symbols = {'N': 0, 'L': 0, 'R': 0, 'e': 0, 'j': 0, # الفئة 0: طبيعي (Class 0: Normal)\n",
        "                  'V': 1, 'E': 1}                         # الفئة 1: VEB (Class 1: VEB)\n",
        "class_names = ['Normal (N)', 'VEB (V)']\n",
        "\n",
        "# تحديد حجم النافذة حول قمة R لاستخلاص قطعة النبضة\n",
        "# Define window size around R-peak for beat segment extraction\n",
        "window_before = int(0.1 * fs) # 100 مللي ثانية قبل القمة (100 ms before peak)\n",
        "window_after = int(0.15 * fs) # 150 مللي ثانية بعد القمة (150 ms after peak)\n",
        "segment_length = window_before + window_after\n",
        "print(f\"Beat segment window: {window_before} samples before R, {window_after} samples after R. Total length: {segment_length} samples.\")\n",
        "\n",
        "segmented_beats = []\n",
        "labels = []\n",
        "rr_intervals_prev = []\n",
        "rr_intervals_next = []\n",
        "beat_rms = []\n",
        "\n",
        "# المرور على جميع النبضات المشروحة\n",
        "# Iterate through all annotated beats\n",
        "# نتجاهل الأولى والأخيرة لسهولة حساب RR (Ignore first and last for easy RR calculation)\n",
        "for i in range(1, len(rpeak_indices_annotated) - 1):\n",
        "    current_beat_index = rpeak_indices_annotated[i]\n",
        "    current_beat_symbol = beat_symbols[i]\n",
        "\n",
        "    # التحقق مما إذا كان نوع النبضة ضمن الفئات المستهدفة\n",
        "    # Check if the beat type is among the target classes\n",
        "    if current_beat_symbol in target_symbols:\n",
        "        # التأكد من أن النافذة لا تخرج عن حدود الإشارة\n",
        "        # Ensure the window does not go out of signal bounds\n",
        "        start = current_beat_index - window_before\n",
        "        end = current_beat_index + window_after\n",
        "        if start >= 0 and end < len(ecg_filtered):\n",
        "            # استخلاص قطعة النبضة\n",
        "            # Extract beat segment\n",
        "            beat_segment = ecg_filtered[start:end]\n",
        "\n",
        "            # Ensure segment has the correct length (sometimes edge cases might cause issues)\n",
        "            if len(beat_segment) == segment_length:\n",
        "                segmented_beats.append(beat_segment)\n",
        "\n",
        "                # إضافة التصنيف (0 أو 1)\n",
        "                # Add the label (0 or 1)\n",
        "                labels.append(target_symbols[current_beat_symbol])\n",
        "\n",
        "                # حساب فترة R-R السابقة واللاحقة (بالثواني)\n",
        "                # Calculate previous and next R-R interval (in seconds)\n",
        "                prev_beat_index = rpeak_indices_annotated[i-1]\n",
        "                next_beat_index = rpeak_indices_annotated[i+1]\n",
        "                rr_prev = (current_beat_index - prev_beat_index) / fs\n",
        "                rr_next = (next_beat_index - current_beat_index) / fs\n",
        "                rr_intervals_prev.append(rr_prev)\n",
        "                rr_intervals_next.append(rr_next)\n",
        "\n",
        "                # حساب ميزة بسيطة للشكل: RMS للقطعة\n",
        "                # Calculate a simple shape feature: RMS of the segment\n",
        "                rms = np.sqrt(np.mean(beat_segment**2))\n",
        "                beat_rms.append(rms)\n",
        "            # else:\n",
        "            #     print(f\"Skipping beat at index {current_beat_index} due to inconsistent segment length: {len(beat_segment)}\")\n",
        "\n",
        "\n",
        "print(f\"Extracted {len(segmented_beats)} beats belonging to target classes.\")\n",
        "# Check if any beats were extracted\n",
        "if not segmented_beats:\n",
        "    print(\"Error: No beats were extracted. Check annotation symbols or windowing logic.\")\n",
        "    exit()\n",
        "\n",
        "unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "print(f\"Class distribution: {dict(zip(unique_labels, counts))}\")\n",
        "\n",
        "# -------------------------------------------\n",
        "# 4. إنشاء مصفوفة الميزات (Feature Matrix)\n",
        "# Create Feature Matrix\n",
        "# -------------------------------------------\n",
        "# الميزات: RR_prev, RR_next, RMS\n",
        "# Features: RR_prev, RR_next, RMS\n",
        "# Note: We could also add morphological features from `segmented_beats`\n",
        "features = np.column_stack((rr_intervals_prev, rr_intervals_next, beat_rms))\n",
        "y = np.array(labels)\n",
        "\n",
        "print(f\"Feature matrix shape: {features.shape}\") # (عدد النبضات × 3 ميزات) (number of beats x 3 features)\n",
        "\n",
        "# -------------------------------------------\n",
        "# 5. تقسيم البيانات وتحجيم الميزات\n",
        "# Data Splitting and Feature Scaling\n",
        "# -------------------------------------------\n",
        "# stratify=y ensures proportional class representation in train/test splits\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.3, random_state=42, stratify=y)\n",
        "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Features scaled using StandardScaler.\")\n",
        "\n",
        "# -------------------------------------------\n",
        "# 6. تدريب مصنف الغابة العشوائية (Random Forest)\n",
        "# Train Random Forest Classifier\n",
        "# -------------------------------------------\n",
        "# n_estimators: عدد الأشجار في الغابة (number of trees in the forest)\n",
        "# max_depth: للتحكم في عمق كل شجرة (يساعد على منع فرط التخصيص)\n",
        "# max_depth: controls the depth of each tree (helps prevent overfitting)\n",
        "# class_weight='balanced': مفيد إذا كانت الفئات غير متوازنة (كما هو الحال غالبًا في ECG)\n",
        "# class_weight='balanced': useful if classes are imbalanced (often the case in ECG)\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10,\n",
        "                                       random_state=42, class_weight='balanced')\n",
        "\n",
        "print(\"\\nTraining Random Forest classifier...\")\n",
        "rf_classifier.fit(X_train_scaled, y_train)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# -------------------------------------------\n",
        "# 7. التنبؤ والتقييم\n",
        "# Prediction and Evaluation\n",
        "# -------------------------------------------\n",
        "print(\"\\nEvaluating Random Forest classifier on the test set...\")\n",
        "y_pred_rf = rf_classifier.predict(X_test_scaled)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Random Forest Confusion Matrix (Record {record_name})')\n",
        "plt.tight_layout()\n",
        "plt.show() # Display the plot\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "report_rf = classification_report(y_test, y_pred_rf, target_names=class_names)\n",
        "print(report_rf)\n",
        "\n",
        "# -------------------------------------------\n",
        "# 8. (اختياري) أهمية الميزات\n",
        "# (Optional) Feature Importances\n",
        "# -------------------------------------------\n",
        "importances = rf_classifier.feature_importances_\n",
        "feature_names_list = ['RR_prev', 'RR_next', 'Beat_RMS']\n",
        "indices = np.argsort(importances)[::-1] # ترتيب الميزات من الأكثر أهمية للأقل (Sort features from most to least important)\n",
        "\n",
        "print(\"\\nFeature Importances:\")\n",
        "for f in range(features.shape[1]):\n",
        "    print(f\"{f + 1}. Feature: {feature_names_list[indices[f]]} ({importances[indices[f]]:.4f})\")\n",
        "\n",
        "# رسم أهمية الميزات\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.title(\"Feature Importances (Random Forest)\")\n",
        "plt.bar(range(features.shape[1]), importances[indices], align='center')\n",
        "plt.xticks(range(features.shape[1]), [feature_names_list[i] for i in indices], rotation=45, ha='right')\n",
        "plt.xlim([-1, features.shape[1]])\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show() # Display the plot\n",
        "\n",
        "print(\"\\nScript finished.\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'wfdb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c6d3e12fcf29>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwfdb\u001b[0m \u001b[0;31m# للتعامل مع بيانات PhysioNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wfdb'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "Wtn6hHKbXXXV",
        "outputId": "e10ab0c0-b87b-41d3-ec05-b9df58ed2c8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add `%load_ext cudf.pandas` before importing pandas to speed up operations using GPU"
      ],
      "metadata": {
        "id": "LSh5BN3VX5Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext cudf.pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Randomly generated dataset of parking violations-\n",
        "# Define the number of rows\n",
        "num_rows = 1000000\n",
        "\n",
        "states = [\"NY\", \"NJ\", \"CA\", \"TX\"]\n",
        "violations = [\"Double Parking\", \"Expired Meter\", \"No Parking\",\n",
        "              \"Fire Hydrant\", \"Bus Stop\"]\n",
        "vehicle_types = [\"SUBN\", \"SDN\"]\n",
        "\n",
        "# Create a date range\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "\n",
        "# Generate random data\n",
        "data = {\n",
        "    \"Registration State\": np.random.choice(states, size=num_rows),\n",
        "    \"Violation Description\": np.random.choice(violations, size=num_rows),\n",
        "    \"Vehicle Body Type\": np.random.choice(vehicle_types, size=num_rows),\n",
        "    \"Issue Date\": np.random.choice(dates, size=num_rows),\n",
        "    \"Ticket Number\": np.random.randint(1000000000, 9999999999, size=num_rows)\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Which parking violation is most commonly committed by vehicles from various U.S states?\n",
        "\n",
        "(df[[\"Registration State\", \"Violation Description\"]]  # get only these two columns\n",
        " .value_counts()  # get the count of offences per state and per type of offence\n",
        " .groupby(\"Registration State\")  # group by state\n",
        " .head(1)  # get the first row in each group (the type of offence with the largest count)\n",
        " .sort_index()  # sort by state name\n",
        " .reset_index()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "bFAL9Vy4X5Rk",
        "outputId": "052b1ea2-d6f8-4ad2-d4ef-ecc5f946c79f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/cudf/utils/_ptxcompiler.py:64: UserWarning: Error getting driver and runtime versions:\n",
            "\n",
            "stdout:\n",
            "\n",
            "\n",
            "\n",
            "stderr:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 4, in <module>\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\", line 314, in __getattr__\n",
            "    raise CudaSupportError(\"Error at driver init: \\n%s:\" %\n",
            "numba.cuda.cudadrv.error.CudaSupportError: Error at driver init: \n",
            "\n",
            "CUDA driver library cannot be found.\n",
            "If you are sure that a CUDA driver is installed,\n",
            "try setting environment variable NUMBA_CUDA_DRIVER\n",
            "with the file path of the CUDA driver shared library.\n",
            ":\n",
            "\n",
            "\n",
            "Not patching Numba\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/cudf/utils/gpu_utils.py:62: UserWarning: Failed to dlopen libcuda.so.1\n",
            "  warnings.warn(str(e))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Function \"cuInit\" not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d614f6eb7df8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cudf.pandas'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Randomly generated dataset of parking violations-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-57>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     85\u001b[0m                               dir=compress_user(self.ipython_extension_dir)))\n\u001b[1;32m     86\u001b[0m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_load_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36m_call_load_ipython_extension\u001b[0;34m(self, mod)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_load_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'load_ipython_extension'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/pandas/magics.py\u001b[0m in \u001b[0;36mload_ipython_extension\u001b[0;34m(ip)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minstall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_magics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCudfPandasMagics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/pandas/__init__.py\u001b[0m in \u001b[0;36minstall\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# The default mode is \"managed_pool\" if UVM is supported, otherwise \"pool\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     managed_memory_is_supported = (\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mpylibcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_concurrent_managed_access_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     default_rmm_mode = (\n",
            "\u001b[0;32mutils.pyx\u001b[0m in \u001b[0;36mpylibcudf.utils._is_concurrent_managed_access_supported\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cuda/bindings/runtime.pyx\u001b[0m in \u001b[0;36mcuda.bindings.runtime.cudaFree\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cuda/bindings/cyruntime.pyx\u001b[0m in \u001b[0;36mcuda.bindings.cyruntime.cudaFree\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cuda/bindings/_lib/cyruntime/cyruntime.pyx\u001b[0m in \u001b[0;36mcuda.bindings._lib.cyruntime.cyruntime._cudaFree\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cuda/bindings/_lib/cyruntime/utils.pyx\u001b[0m in \u001b[0;36mcuda.bindings._lib.cyruntime.utils.cudaPythonGlobal.lazyInitContextState\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cuda/bindings/_lib/cyruntime/utils.pyx\u001b[0m in \u001b[0;36mcuda.bindings._lib.cyruntime.utils.cudaPythonGlobal.lazyInitDriver\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cuda/bindings/_bindings/cydriver.pyx\u001b[0m in \u001b[0;36mcuda.bindings._bindings.cydriver._cuInit\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Function \"cuInit\" not found"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}